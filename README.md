# Pomone - D√©tection de Mauvaises Herbes en Temps R√©el

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![YOLOv11](https://img.shields.io/badge/YOLO-v11-green.svg)](https://github.com/ultralytics/ultralytics)

**Pomone** est un syst√®me de d√©tection de mauvaises herbes en temps r√©el utilisant YOLO et une interface HUD (Heads-Up Display) transparente. Le syst√®me capture l'√©cran en continu, effectue des inf√©rences de d√©tection d'objets et affiche les r√©sultats sous forme d'overlay transparent par-dessus n'importe quelle application.

## üåø √Ä Propos

Ce projet impl√©mente un syst√®me de d√©tection capable d'identifier **25 types de mauvaises herbes** diff√©rentes en temps r√©el. L'overlay transparent permet de visualiser les d√©tections sans interrompre le flux de travail, id√©al pour l'analyse d'images agricoles, la recherche ou l'√©ducation.

### Classes D√©tect√©es

Le mod√®le peut identifier les 25 esp√®ces de mauvaises herbes suivantes :

- Alligatorweed
- Asiatic Smartweed
- Bidens pilosa
- Black nightshade
- Ceylon spinach
- Chinese knotweed
- Common Dayflower
- Indian aster
- Mock strawberry
- Shepherd's Purse
- Viola
- Abutilon theophrasti
- Barnyard grass
- Billygoat weed
- Cocklebur
- Crabgrass
- Field thistle
- Goosefoots
- Green foxtail
- Horseweed
- Pigweed
- Plantain
- Purslane
- Sedge
- White smart weed

## üìä Dataset

Ce projet utilise le dataset **Weed25** disponible sur Roboflow Universe :

- **Nom du dataset** : Weed25 Labeling
- **Workspace** : weed25-dataset
- **Version** : 4
- **Licence** : CC BY 4.0
- **URL** : [https://universe.roboflow.com/weed25-dataset/weed25-labeling/dataset/4](https://universe.roboflow.com/weed25-dataset/weed25-labeling/dataset/4)

Le dataset contient des images annot√©es de 25 esp√®ces diff√©rentes de mauvaises herbes, permettant l'entra√Ænement de mod√®les de d√©tection d'objets pour l'agriculture de pr√©cision.

## ‚ú® Fonctionnalit√©s

- üéØ **D√©tection en temps r√©el** : Inf√©rence continue sur la capture d'√©cran
- ü™ü **Overlay transparent** : Affichage HUD non-intrusif par-dessus n'importe quelle application
- üñ•Ô∏è **Support multi-moniteurs** : S√©lection du moniteur √† capturer
- ‚ö° **Acc√©l√©ration GPU** : Support CUDA pour des performances optimales
- üìä **Affichage FPS** : Statistiques de performance en temps r√©el
- üé® **Couleurs par classe** : Chaque esp√®ce a une couleur distinctive
- ‚öôÔ∏è **Hautement configurable** : Seuils de confiance, taille d'inf√©rence, intervalle de frames, etc.

## üöÄ Installation

### Pr√©requis

- Python 3.8 ou sup√©rieur
- GPU NVIDIA avec support CUDA (recommand√© pour de meilleures performances)
- Windows, Linux ou macOS

### Installation des D√©pendances

1. Clonez le d√©p√¥t :
```bash
git clone https://github.com/votre-username/pomone.git
cd pomone
```

2. Installez les d√©pendances :
```bash
pip install -r requirements.txt
```

Les principales d√©pendances incluent :
- `ultralytics` : Framework YOLO
- `opencv-python` : Traitement d'images
- `PyQt5` : Interface graphique overlay
- `mss` : Capture d'√©cran rapide
- `torch` : Backend PyTorch avec support CUDA

## üìñ Utilisation

### D√©marrage Rapide

```bash
python overlay.py --weights runs/detect/train/weights/best.pt --data Architecture/data.yaml --show-fps
```

### Lister les Moniteurs Disponibles

```bash
python overlay.py --list-monitors
```

### Options de Ligne de Commande

| Option | Type | D√©faut | Description |
|--------|------|--------|-------------|
| `--weights` | Path | `runs/detect/train/weights/best.pt` | Chemin vers le fichier de poids YOLO |
| `--data` | Path | `None` | Fichier YAML du dataset pour les noms de classes |
| `--monitor` | int | `1` | Index du moniteur √† capturer |
| `--list-monitors` | flag | - | Liste les moniteurs disponibles et quitte |
| `--conf` | float | `0.25` | Seuil de confiance pour les d√©tections |
| `--frame-interval` | float | `0.05` | D√©lai minimum entre les inf√©rences (secondes) |
| `--device` | str | `None` | Identifiant du device Torch (ex: '0' ou 'cpu') |
| `--imgsz` | int | `None` | Taille d'image pour l'inf√©rence |
| `--show-fps` | flag | - | Affiche le compteur d'objets et les FPS |
| `--thickness` | int | `3` | √âpaisseur des bo√Ætes englobantes (pixels) |
| `--font-size` | int | `14` | Taille de la police de l'overlay (points) |

### Exemples d'Utilisation

**D√©tection avec affichage FPS et seuil de confiance √©lev√© :**
```bash
python overlay.py --weights yolo11n.pt --data Architecture/data.yaml --conf 0.5 --show-fps
```

**Utilisation du CPU uniquement :**
```bash
python overlay.py --weights yolo11n.pt --device cpu
```

**Capture du deuxi√®me moniteur avec inf√©rence plus lente :**
```bash
python overlay.py --monitor 2 --frame-interval 0.1
```

**Personnalisation de l'apparence :**
```bash
python overlay.py --thickness 5 --font-size 16 --show-fps
```

## üèóÔ∏è Architecture

Le projet est structur√© autour de trois composants principaux :

### 1. `DetectionWorker` (Thread)
- Capture l'√©cran en continu avec `mss`
- Effectue les inf√©rences YOLO sur chaque frame
- Transmet les d√©tections au composant d'affichage

### 2. `DetectionOverlay` (QWidget)
- Fen√™tre PyQt5 transparente et toujours au premier plan
- Re√ßoit les d√©tections et les affiche
- G√®re le rendu des bo√Ætes englobantes et des labels

### 3. Syst√®me de D√©tection
- Chargement du mod√®le YOLO
- R√©solution des noms de classes depuis le fichier data.yaml
- Post-traitement des r√©sultats d'inf√©rence

## üéì Entra√Ænement du Mod√®le

Pour entra√Æner votre propre mod√®le sur le dataset Weed25 :

```python
from ultralytics import YOLO

# Charger un mod√®le pr√©-entra√Æn√©
model = YOLO('yolo11n.pt')

# Entra√Æner le mod√®le
results = model.train(
    data='Architecture/data.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    device=0  # GPU
)
```

Les poids entra√Æn√©s seront sauvegard√©s dans `runs/detect/train/weights/best.pt`.

## üõ†Ô∏è Configuration

Le fichier `Architecture/data.yaml` contient la configuration du dataset :

```yaml
train: ../train/images
val: ../valid/images
test: ../test/images

nc: 25
names: ['Alligatorweed', 'Asiatic_Smartweed', ...]

roboflow:
  workspace: weed25-dataset
  project: weed25-labeling
  version: 4
  license: CC BY 4.0
  url: https://universe.roboflow.com/weed25-dataset/weed25-labeling/dataset/4
```

## üîß D√©pannage

### L'overlay ne s'affiche pas
- V√©rifiez que le fichier de poids existe
- Assurez-vous que PyQt5 est correctement install√©
- Essayez de changer le moniteur avec `--monitor`

### Performances faibles
- Utilisez un GPU avec `--device 0`
- Augmentez `--frame-interval` pour r√©duire la fr√©quence d'inf√©rence
- Utilisez un mod√®le plus petit (yolo11n.pt au lieu de yolo11s.pt)
- R√©duisez `--imgsz` pour des inf√©rences plus rapides

### Erreurs CUDA
- V√©rifiez que PyTorch est install√© avec support CUDA
- Utilisez `--device cpu` pour forcer l'utilisation du CPU

## üìù Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

Le dataset utilis√© (Weed25) est sous licence **CC BY 4.0**.

## üôè Remerciements

- **Roboflow** pour l'h√©bergement du dataset Weed25
- **Ultralytics** pour le framework YOLO
- La communaut√© open-source pour les outils et biblioth√®ques utilis√©s

## üìß Contact

Pour toute question ou suggestion, n'h√©sitez pas √† ouvrir une issue sur GitHub.

---

**Note** : Ce projet est destin√© √† des fins √©ducatives et de recherche. Pour une utilisation en production dans des applications agricoles, des tests et validations suppl√©mentaires sont recommand√©s.
